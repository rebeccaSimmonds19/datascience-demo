{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8a7c6528e9923407a2ac42471bffeaf3ee32679"
   },
   "source": [
    "# Predicting points based on description (NLP) and other features with Catboost\n",
    "\n",
    "add in the graphs on top of here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "34db8811fbdfe85242c9c86ff7f36ca9067f85bb"
   },
   "source": [
    "First of all, we are going to load our data and clean the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('wine-reviews/winemag-data-130k-v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "88695da049b1cfbfee5fa5f37b58323a5e8ff5c6"
   },
   "outputs": [],
   "source": [
    "data=data.dropna(subset=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "fba0b411165819103f0ddc93a8d4afb6ac48b8dd"
   },
   "outputs": [],
   "source": [
    "data=data.drop_duplicates(['description','title'])\n",
    "data=data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "05de805d22e0bb89ebfa953a13b18e078674a3e4"
   },
   "outputs": [],
   "source": [
    "data=data.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "187c7786e47b00ab0c94bdbba2fe027f191ff5f0"
   },
   "source": [
    "# NLP\n",
    "Our basic features are ready, so now we start to create features from description with using NLTK library.\n",
    "NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,” and “an amazing library to play with natural language.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "6816ed0f935779feec1522abc9f31b08a3ef8395"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c7df6a941dd49db86a274736bf0bcb41f42440c"
   },
   "source": [
    "We have to turn evry word into lowercase because there is no meaning diffrence between 'This' and 'this' term. We also get rid of irrelevent term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "d0a950d978c6b3206376b30905042b9f3d046e02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         this is ripe and fruity  a wine that is smooth...\n",
       "1         tart and snappy  the flavors of lime flesh and...\n",
       "2         pineapple rind  lemon pith and orange blossom ...\n",
       "3         much like the regular bottling from       this...\n",
       "4         blackberry and raspberry aromas show a typical...\n",
       "5         here s a bright  informal red that opens with ...\n",
       "6         this dry and restrained wine offers spice in p...\n",
       "7         savory dried thyme notes accent sunnier flavor...\n",
       "8         this has great depth of flavor with its fresh ...\n",
       "9         soft  supple plum envelopes an oaky structure ...\n",
       "10        this is a dry wine  very spicy  with a tight  ...\n",
       "11        slightly reduced  this wine offers a chalky  t...\n",
       "12        building on     years and six generations of w...\n",
       "13        zesty orange peels and apple notes abound in t...\n",
       "14        baked plum  molasses  balsamic vinegar and che...\n",
       "15        raw black cherry aromas are direct and simple ...\n",
       "16        desiccated blackberry  leather  charred wood a...\n",
       "17        red fruit aromas pervade on the nose  with cig...\n",
       "18        ripe aromas of dark berries mingle with ample ...\n",
       "19        a sleek mix of tart berry  stem and herb  alon...\n",
       "20        delicate aromas recall white flower and citrus...\n",
       "21        this wine from the geneseo district offers aro...\n",
       "22        aromas of prune  blackcurrant  toast and oak c...\n",
       "23        oak and earth intermingle around robust aromas...\n",
       "24        pretty aromas of yellow flower and stone fruit...\n",
       "25        aromas recall ripe dark berry  toast and a whi...\n",
       "26        aromas suggest mature berry  scorched earth  a...\n",
       "27        clarksburg is becoming a haven for chenin blan...\n",
       "28        rustic and dry  this has flavors of berries  c...\n",
       "29        this shows a tart  green gooseberry flavor tha...\n",
       "                                ...                        \n",
       "111563    this is the winery s bells and whistles chardo...\n",
       "111564    a chardonnay with an unusual companion     s m...\n",
       "111565    this is classic in herbaceous aromas and flavo...\n",
       "111566    a blend of nero d avola and syrah  this convey...\n",
       "111567    deep garnet in the glass  this has a nose of b...\n",
       "111568    hailing from one of the more popular vineyards...\n",
       "111569    plump  clingy peach and honey notes are cut wi...\n",
       "111570    a blend of     cabernet sauvignon      merlot ...\n",
       "111571    raspberry and cassis aromas are fresh and upri...\n",
       "111572    there s no bones about the use of oak in this ...\n",
       "111573    this opens with herbaceous dollops of thyme an...\n",
       "111574    hugely spicy this rich wine is described as sw...\n",
       "111575    this zinfandel from the eastern section of nap...\n",
       "111576    roughly two thirds cabernet and one third merl...\n",
       "111577    one of the more characterful pinot gris for th...\n",
       "111578    like dog point s      chardonnay  this wine is...\n",
       "111579    the blend is     merlot      cabernet sauvigno...\n",
       "111580    lightly baked berry aromas vie for attention w...\n",
       "111581    this blend of cabernet sauvignon merlot and ca...\n",
       "111582    the granite soil of the brand grand cru vineya...\n",
       "111583    fresh and fruity  this is full of red cherry f...\n",
       "111584    intense aromas of wild cherry  baking spice  t...\n",
       "111585    blackberry  cassis  grilled herb and toasted a...\n",
       "111586    a bouquet of black cherry  tart cranberry and ...\n",
       "111587    while it s rich  this beautiful dry wine also ...\n",
       "111588    notes of honeysuckle and cantaloupe sweeten th...\n",
       "111589    citation is given as much as a decade of bottl...\n",
       "111590    well drained gravel soil gives this wine its c...\n",
       "111591    a dry style of pinot gris  this is crisp with ...\n",
       "111592    big  rich and off dry  this is powered by inte...\n",
       "Name: description, Length: 111593, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description']= data['description'].str.lower()\n",
    "data['description']= data['description'].apply(lambda elem: re.sub('[^a-zA-Z]',' ', elem))  \n",
    "data['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c88d0cae1616cfb2dfeb6c29c9dbc927c891fa6"
   },
   "source": [
    "We can't analyze whole sentences, we will use regex to tokenize sentences to list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "bb18ae1ab19fc6b6b2d8f53f2f1db04bc5ae2433"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [this, is, ripe, and, fruity, a, wine, that, i...\n",
       "1    [tart, and, snappy, the, flavors, of, lime, fl...\n",
       "2    [pineapple, rind, lemon, pith, and, orange, bl...\n",
       "3    [much, like, the, regular, bottling, from, thi...\n",
       "4    [blackberry, and, raspberry, aromas, show, a, ...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "words_descriptions = data['description'].apply(tokenizer.tokenize)\n",
    "words_descriptions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf73aaf3d935b0934d8d84c4d6bf74f8fdd66917"
   },
   "source": [
    "When we split description into individual words, we have to create vocabulary and additionaly we can add new feature - description lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "c90fcac6315bd41fdf62c359db6a84d410dc07cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4624968 words total, with a vocabulary size of 29486\n"
     ]
    }
   ],
   "source": [
    "all_words = [word for tokens in words_descriptions for word in tokens]\n",
    "data['description_lengths']= [len(tokens) for tokens in words_descriptions]\n",
    "VOCAB = sorted(list(set(all_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "16f8a4a5ea21e877d0a847f48e548a1f66e332bc"
   },
   "source": [
    "Let's check what are our most common words in our dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "2e36207a4148bf41368ed6ec66226f00a5767373"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 302908),\n",
       " ('the', 190834),\n",
       " ('a', 154824),\n",
       " ('of', 149861),\n",
       " ('with', 104095),\n",
       " ('this', 98014),\n",
       " ('is', 81926),\n",
       " ('it', 74638),\n",
       " ('wine', 66708),\n",
       " ('flavors', 55626),\n",
       " ('in', 55172),\n",
       " ('to', 48455),\n",
       " ('s', 46898),\n",
       " ('fruit', 42627),\n",
       " ('on', 40239),\n",
       " ('that', 34359),\n",
       " ('aromas', 34293),\n",
       " ('palate', 33563),\n",
       " ('finish', 30983),\n",
       " ('acidity', 28935),\n",
       " ('from', 27774),\n",
       " ('but', 27565),\n",
       " ('tannins', 25883),\n",
       " ('drink', 25692),\n",
       " ('cherry', 25586),\n",
       " ('black', 24936),\n",
       " ('are', 22572),\n",
       " ('ripe', 22538),\n",
       " ('has', 20419),\n",
       " ('for', 19024),\n",
       " ('red', 18603),\n",
       " ('by', 17485),\n",
       " ('notes', 16619),\n",
       " ('spice', 16210),\n",
       " ('oak', 16022),\n",
       " ('an', 15673),\n",
       " ('as', 15504),\n",
       " ('its', 15195),\n",
       " ('dry', 15044),\n",
       " ('nose', 14962),\n",
       " ('now', 14954),\n",
       " ('rich', 14690),\n",
       " ('berry', 14530),\n",
       " ('fresh', 14506),\n",
       " ('full', 13629),\n",
       " ('plum', 13077),\n",
       " ('sweet', 11813),\n",
       " ('apple', 11652),\n",
       " ('blend', 11580),\n",
       " ('soft', 11563),\n",
       " ('blackberry', 11319),\n",
       " ('well', 11317),\n",
       " ('white', 11010),\n",
       " ('fruits', 10844),\n",
       " ('light', 10839),\n",
       " ('crisp', 10726),\n",
       " ('offers', 10660),\n",
       " ('dark', 10575),\n",
       " ('texture', 10401),\n",
       " ('bodied', 10165),\n",
       " ('citrus', 10109),\n",
       " ('while', 10093),\n",
       " ('there', 10031),\n",
       " ('shows', 9884),\n",
       " ('through', 9877),\n",
       " ('vanilla', 9828),\n",
       " ('cabernet', 9698),\n",
       " ('bright', 9059),\n",
       " ('at', 9003),\n",
       " ('pepper', 8979),\n",
       " ('more', 8831),\n",
       " ('very', 8620),\n",
       " ('green', 8485),\n",
       " ('raspberry', 8475),\n",
       " ('good', 8440),\n",
       " ('lemon', 8293),\n",
       " ('juicy', 8174),\n",
       " ('fruity', 7776),\n",
       " ('chocolate', 7717),\n",
       " ('some', 7702),\n",
       " ('firm', 7527),\n",
       " ('peach', 7512),\n",
       " ('like', 7400),\n",
       " ('not', 7286),\n",
       " ('balanced', 7283),\n",
       " ('touch', 7199),\n",
       " ('will', 6912),\n",
       " ('up', 6896),\n",
       " ('dried', 6834),\n",
       " ('sauvignon', 6832),\n",
       " ('pear', 6778),\n",
       " ('out', 6719),\n",
       " ('years', 6629),\n",
       " ('or', 6511),\n",
       " ('character', 6493),\n",
       " ('spicy', 6310),\n",
       " ('be', 6266),\n",
       " ('all', 6224),\n",
       " ('structure', 6143),\n",
       " ('fine', 6142)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count_all_words = Counter(all_words)\n",
    "count_all_words.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "64d9aeebd7feeb929088ea55d07124626cc9fda4"
   },
   "source": [
    "We can see that there are many stop words and words which can't help us with our goal - predict points. \n",
    "Now we want to\n",
    "1. Convert words with same meaning to the one word(example run, running, runned -> run). We will use PorterStemmer from NLTK library.\n",
    "2. Delete all stopwords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "d0b244e4a7f750c7d4146269a7e73e79d0d36e0a"
   },
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "ps = PorterStemmer()\n",
    "words_descriptions = words_descriptions.apply(lambda elem: [word for word in elem if not word in stopword_list])\n",
    "words_descriptions = words_descriptions.apply(lambda elem: [ps.stem(word) for word in elem])\n",
    "data['description_cleaned'] = words_descriptions.apply(lambda elem: ' '.join(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "b39a3090275ea9829feb4ac0c4818a98c31840bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2822364 words total, with a vocabulary size of 21073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('wine', 69125),\n",
       " ('flavor', 62686),\n",
       " ('fruit', 53836),\n",
       " ('finish', 35863),\n",
       " ('aroma', 35564),\n",
       " ('palat', 33674),\n",
       " ('acid', 33330),\n",
       " ('cherri', 29505),\n",
       " ('drink', 28905),\n",
       " ('tannin', 27717),\n",
       " ('black', 24963),\n",
       " ('ripe', 24037),\n",
       " ('dri', 22844),\n",
       " ('note', 21892),\n",
       " ('spice', 20040),\n",
       " ('red', 18821),\n",
       " ('rich', 18382),\n",
       " ('fresh', 18095),\n",
       " ('berri', 16569),\n",
       " ('oak', 16557),\n",
       " ('show', 15940),\n",
       " ('nose', 14976),\n",
       " ('plum', 14252),\n",
       " ('sweet', 13919),\n",
       " ('full', 13729),\n",
       " ('offer', 13698),\n",
       " ('blackberri', 13395),\n",
       " ('textur', 13370),\n",
       " ('blend', 13280),\n",
       " ('appl', 13155),\n",
       " ('balanc', 13005),\n",
       " ('bodi', 13003),\n",
       " ('soft', 12045),\n",
       " ('age', 11719),\n",
       " ('crisp', 11409),\n",
       " ('well', 11328),\n",
       " ('white', 11150),\n",
       " ('light', 11149),\n",
       " ('dark', 10653),\n",
       " ('structur', 10643),\n",
       " ('citru', 10109),\n",
       " ('raspberri', 9909),\n",
       " ('cabernet', 9858),\n",
       " ('vanilla', 9829),\n",
       " ('hint', 9750),\n",
       " ('herb', 9717),\n",
       " ('miner', 9669),\n",
       " ('fruiti', 9653),\n",
       " ('bright', 9380),\n",
       " ('give', 9222),\n",
       " ('pepper', 9131),\n",
       " ('touch', 8885),\n",
       " ('lemon', 8666),\n",
       " ('year', 8657),\n",
       " ('green', 8655),\n",
       " ('good', 8557),\n",
       " ('juici', 8480),\n",
       " ('peach', 8287),\n",
       " ('feel', 8027),\n",
       " ('like', 7993),\n",
       " ('concentr', 7933),\n",
       " ('chocol', 7718),\n",
       " ('firm', 7696),\n",
       " ('pear', 7571),\n",
       " ('complex', 7535),\n",
       " ('currant', 7453),\n",
       " ('vineyard', 7405),\n",
       " ('toast', 7373),\n",
       " ('fine', 6890),\n",
       " ('come', 6858),\n",
       " ('sauvignon', 6857),\n",
       " ('open', 6794),\n",
       " ('charact', 6592),\n",
       " ('spici', 6558),\n",
       " ('pinot', 6445),\n",
       " ('smooth', 6412),\n",
       " ('tast', 6287),\n",
       " ('make', 6184),\n",
       " ('bottl', 6181),\n",
       " ('tart', 6126),\n",
       " ('made', 6114),\n",
       " ('style', 6110),\n",
       " ('eleg', 6029),\n",
       " ('medium', 6008),\n",
       " ('mouth', 5831),\n",
       " ('lead', 5827),\n",
       " ('round', 5789),\n",
       " ('intens', 5751),\n",
       " ('long', 5678),\n",
       " ('herbal', 5660),\n",
       " ('lime', 5605),\n",
       " ('tannic', 5534),\n",
       " ('wood', 5524),\n",
       " ('orang', 5408),\n",
       " ('merlot', 5371),\n",
       " ('bit', 5369),\n",
       " ('bake', 5336),\n",
       " ('also', 5308),\n",
       " ('creami', 5263),\n",
       " ('licoric', 5216)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = [word for tokens in words_descriptions for word in tokens]\n",
    "VOCAB = sorted(list(set(all_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))\n",
    "count_all_words = Counter(all_words)\n",
    "count_all_words.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "526e0112ec031590725aec4ba54372617fb5a7fd"
   },
   "source": [
    "As we can see we deleted almost 9k words and now words from description are much more meaningful.\n",
    "Now we can 3 diffrent ways to represent our description\n",
    "\n",
    "1. **Bag of Words Counts** - embeds each sentences as a list of 0 or 1,  1 represent containing word. \n",
    "2. **TF-IDF (Term Frequency, Inverse Document Frequency)** - weighing words by how frequent they are in our dataset, discounting words that are too frequent.\n",
    "3. **Word2Vec **- Capturing semantic meaning. We won't use it in this kernel.\n",
    "\n",
    "We will check which types perform better in our case, Bag of Words Counts or TF-IDF Bag of Words.\n",
    "\n",
    "First we will test Bag of Words Counts.\n",
    "\n",
    "Let's define some useful function and then test our picked techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "263347ba58de75c86b65886357729fa21e6ed87a"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import Pool, CatBoostRegressor, cv\n",
    "\n",
    "def prepare_dataframe(vect, data, features=True):\n",
    "    vectorized=vect.fit_transform(data['description_cleaned']).toarray()\n",
    "    vectorized=pd.DataFrame(vectorized)\n",
    "    if features == True:\n",
    "        X=data.drop(columns=['points','Unnamed: 0','description','description_cleaned'])\n",
    "        X=X.fillna(-1)\n",
    "        print(X.columns)\n",
    "        X=pd.concat([X.reset_index(drop=True),vectorized.reset_index(drop=True)],axis=1)\n",
    "        categorical_features_indices =[0,1,3,4,5,6,7,8,9,10]\n",
    "    else:\n",
    "        X=vectorized\n",
    "        categorical_features_indices =[]\n",
    "    y=data['points']\n",
    "    return X,y,categorical_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "a8ded5683a180a94a5c262c474fb76bc33c93824"
   },
   "outputs": [],
   "source": [
    "#model definintion and training.\n",
    "def perform_model(X_train, y_train,X_valid, y_valid,X_test, y_test,categorical_features_indices,name):\n",
    "    model = CatBoostRegressor(\n",
    "        random_seed = 100,\n",
    "        loss_function = 'RMSE',\n",
    "        iterations=800,\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        cat_features = categorical_features_indices,\n",
    "        verbose=False,\n",
    "        eval_set=(X_valid, y_valid)\n",
    "    )\n",
    "    \n",
    "    print(name+\" technique RMSE on training data: \"+ model.score(X_train, y_train).astype(str))\n",
    "    print(name+\" technique RMSE on test data: \"+ model.score(X_test, y_test).astype(str))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "b6027dd40421e3e0d24a504e46cfc7256e82cf0e"
   },
   "outputs": [],
   "source": [
    "def prepare_variable(vect, data, features_append=True):\n",
    "    X, y , categorical_features_indices = prepare_dataframe(vect, data,features_append)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, \n",
    "                                                        random_state=42)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, \n",
    "                                                        random_state=52)\n",
    "    return X_train, y_train,X_valid, y_valid,X_test, y_test, categorical_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "020c5f00f339e8a0ce1890cae5d8d52dd7382caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['country', 'designation', 'price', 'province', 'region_1', 'region_2',\n",
      "       'taster_name', 'taster_twitter_handle', 'title', 'variety', 'winery',\n",
      "       'description_lengths'],\n",
      "      dtype='object')\n",
      "Bag of Words Counts technique RMSE on training data: 1.5107158933234435\n",
      "Bag of Words Counts technique RMSE on test data: 1.5872264225695767\n"
     ]
    }
   ],
   "source": [
    "vect= CountVectorizer(analyzer='word', token_pattern=r'\\w+',max_features=500)\n",
    "training_variable=prepare_variable(vect, data)\n",
    "perform_model(*training_variable, 'Bag of Words Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5a433523b8bc7029e9996d127fe7fae4ab04017",
    "collapsed": true
   },
   "source": [
    "Now we can try TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e68b71556689df5e1802d457f50bf2d6cc3076e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect= TfidfVectorizer(analyzer='word', token_pattern=r'\\w+',max_features=500)\n",
    "training_variable=prepare_variable(vect, data)\n",
    "perform_model(*training_variable, 'TF-IDF')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5be9e5ab37f54035a5896456758c0a01a97e363b"
   },
   "source": [
    "Yeah, but beyond description we used also meaningful features, let's drop all of our features and do prediction based ONLY on descriptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cae27aacac029dcd1861f6ff48d5599c9c6b8210",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect= CountVectorizer(analyzer='word', token_pattern=r'\\w+',max_features=500)\n",
    "training_variable=prepare_variable(vect, data, False)\n",
    "perform_model(*training_variable, 'Bag of Words Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39047ebc7236ef0bfe480ee65c82d994e1d30978",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect= TfidfVectorizer(analyzer='word', token_pattern=r'\\w+',max_features=500)\n",
    "training_variable=prepare_variable(vect, data, False)\n",
    "perform_model(*training_variable, 'TF-IDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ad44cef4cf684a11217dd8a96b93fbbbd562df1",
    "collapsed": true
   },
   "source": [
    "As we can see our scores are similar, but it really outperformet technique without any NLP operations (about 2.09 test score) \n",
    "* 1. link to EDA +  Catboost without NLP : https://www.kaggle.com/mistrzuniu1/eda-catboost-feature-importance/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
